{{Infobox Plugin
| name                   = Elastic Align and Montage
| software               = Fiji
| author                  = [[User:Saalfeld|Stephan Saalfeld]] ([mailto:saalfeld@mpi-cbg.de])
| maintainer             = [[User:Saalfeld|Stephan Saalfeld]]
| source                 = [http://pacific.mpi-cbg.de/cgi-bin/gitweb.cgi?p=mpicbg.git;a=tree;f=mpicbg/ij/plugin]
| released               = March 11<sup>th</sup>, 2011
| latest version         = March 11<sup>th</sup>, 2011
| status                 = experimental, active
| category               = [[:Category:Plugins|Plugins]], [[:Category:Registration|Registration]]
}}
==Introduction==

The plugins '''Elastic Stack Alignment''' and '''Elastic Montage''' implement automatic elastic registration of 2d-images.  The applications are:

;Elastig Montage
:montaging mosaics from overlapping tiles where the tiles have non-linear relative deformation
;Elastic Stack Alignment
:alignment of deformed section series from serially sectioned volumes

Images are warped such that corresponding regions overlap optimally.  The warp for each single image is calculated such that each image in the whole global montage or series will be deformed minimally.  That way, arbitrarily large series of images can be aligned without accumulating artificial warps.

==Elastic Deformation with Spring Meshes==

[[Image:Mesh.png|thumb|right|166px|Fig. 1: Triangular section mesh with a resolution of 5 vertices per each long row.]]
We achieve this globally minimized deformation by simulating the alignment as an elastic system of spring connected vertices.  Zero-length springs connect corresponding locations between two overlapping images and warp the images towards perfect overlap.  Non-zero length springs within the image preserve each images shape at locally rigid transformation.  That way, the system penalizes arbitrary warp and distributes the deformation evenly among all images.

Each image is tessellated into a mesh of regular triangles with each vertex being connected to its neighboring vertices by a spring (see Fig. 1).  A triangle of springs has two families of of cost minima in the plane: 1) at rigid transformations and 2) at rigid transformations flipped.  That is, for all local deformations smaller than the size of a triangle, the mesh will drag towards a rigid transformation.  For larger deformation, it may fold.  The vertices of a triangel define an affine transformation for all pixels in the triangle.

For those vertices of a source image overlapping a target image, we identify its corresponding location in the target image.  The vertex is then connected into the target mesh by a zero-length spring with its target end being located at an arbitrary place in a triangle of the target mesh.  This `passive' end does not contribute to the deformation of the target mesh.  During simulation, it moves according to the affine transformation defined by the target triangle.  Vice versa, vertices of the target image are connected to their corresponding location in the source image with their `passive' ends being moved by the respective affine transformation of a source triangle.

==Linear Initialization==

Both relaxing the system of meshes and identifying corresponding locations between images require good initialization.  The former because the meshes will fold otherwise, the latter to narrow the matching space with the benefit of both, increased speed and better reliability.  We initialize the system with a linear-per-image optimal pre-alignment based on [[Feature Extraction|local image features]].<ref name="SaalfeldAl2010">{{cite journal
| title = As-rigid-as-possible mosaicking and serial section registration of large ssTEM datasets
| author = S. Saalfeld, A. Cardona, V. Hartenstein, P. Tomancak
| journal = Bioinformatics
| pages = i57&ndash;i63
| volume = 26
| number = 12
| year = 2010
| doi = 10.1093/bioinformatics/btq219
}}</ref>

==Block Matching==

[[Image:Correlation.png|thumb|right|361px|Fig. 2: Match filter based on the correlation surface. Starting from an approximate alignment (e.g. affine), for each vertex of the spring mesh, an offset is searched calculating the PMCC coefficient r of a block at all possible x,y translations in a given local vicinity over the overlapping image. The above windows display six examples of such correlation surfaces for translations in a square region with the origin in the middle. The [http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient PMCC coefficent] r is grey-coded in the range from -0.7 to 0.7. The candidate for the translational offset is the translation with maximal r. Candidates are rejected if either r was too low (not similar), there was more than one maximum with very similar r (ambiguous), the maximum is not well localized in both dimensions (an edge pattern that fits everywhere alongside the edge). ]]
Corresponding locations are searched through block matching.  Initialized from an approximate linear pairwise alignment that is estimated using [[Feature Extraction|local image features]], the local vicinity around each vertex is inspected for an optimal match.  We use the The [http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient PMCC coefficent] ''r'' of a patch around the vertex and the overlapping patch in the other image as the quality measure for a match.  The location with maximal ''r'' specifies the offset of the vertex relative to the initial linear alignment.

We perform block matching at a reasonably down-scaled version of the images.  The ideal scaling factor depends on the application and quality of the signal.  To overcome the reduced accuracy off the estimated offset, we use Brown's method<ref name="BrownL2002">{{cite conference
| author = M. Brown and D. Lowe
| title = Invariant Features from Interest Point Groups
| booktitle = British Machine Vision Conference
| year = 2002
| pages = 656&ndash;665
| place = Cardiff, Wales
}}</ref> to estimate an approximate sub-pixel offset.  Furthermore, in order to reject wrong matches, three local filters based on the correlation surface are in place:

;minimal threshold for ''r''
:if the match has an ''r'' lower than a given threshold it is rejected
;edge response filter
:if the principal curvatures of ''r(x,y)'' at matches location are related by a factor larger than a given threshold, the match is rejected for being an edge response.<ref name="Lowe2004">{{cite journal
| author = D. Lowe
| title = Distinctive Image Features from Scale-Invariant Keypoints
| journal = International Journal of Computer Vision
| volume = 60
| number = 2
| pages = 91&ndash;110
| year = 2004
| doi = 10.1109/ICCV.1999.790410
}}</ref>
;ambiguity filter
:if the second best ''r(x,y)'' is very similar to the best, the match is rejected for being ambiguous.  Similar means related by a factor larger than a given threshold.<ref name="Lowe2004" />

==Parameter Discussion==

[[Image:Edge-filter.png|thumb|right|247px|Fig. 3: Edge response filter. The ratio of the two principal curvatures (Hessian eigenvalues) of at a detection determines how well it is defined in both dimensions. A large ratio signalizes an edge response.]]
;Input
:Both plugins work with stacks of images.  The stacks might be virtual, which is strongly suggested for very large images.

;Output
:The plugins export their output as a file or a series of files respectively.  In addition, previously extracted [[Feature Extraction|local features]] and [[Feature Extraction|feature correspondences]] are saved for later re-use during parameter triggering (thanks to [http://albert.rierol.net/ Albert Cardona] for adding this).  Make sure that you work in a clear folder when changing the input data because both saved matches and features are identified by their stack index and parameters only.
:You can choose whether to '''interpolate''' the result or not.  '''Visualize''' checked will render the spring mesh simulation into a 512&times;512 pixel stack for demonstration purposes.  The result is rendered using a transform mesh similar to the spring mesh discussed above.  The parameter '''resolution''' specifies the number of vertices in a long row for this mesh, higher numbers give smoother results.  Usually, you will never need more than '''128'''.

;Feature Extraction
:Find documentation at the [[Feature Extraction]] page.  Note that the '''max error''' relative to the approximate linear transformation model will be used as the maximum search distance during block matching.  The approximate model as specified in this dialog is used for geometric consensus filter and pairwise pre-alignment only.  It should approximate the actual deformation as closely as possible.  That is, you should select an '''affine transformation''' in almost any case.
:In the ''montage plugin'', all images are compared to each other.  This is prohibitive for montages consisting of a large number of images and will change in the future.  Also in the ''series alignment'', we try to establish matches not only to adjacent section in the series but to as many sections as possible.  Since the similarity of two section decreases with increasing distance, we can stop matching sections after we have failed to compare closer partners.  Still, we want to be able to bridge sections with bad quality or exceptional artifacts.  You can specify how many '''failures''' you may be willing to bridge.

;Block Matching
:Here you specifiy the downscaled '''image size''' at which matching is performed.  Choose this size such that 1) high level noise is effectively invisible, 2) for series alignment such that a pixel is approximately as large as (or larger than) the section thickness.  The threshold for '''min r''' can be higher for montaging (same signal) than for series alignment (changing signal).  Higher values will lead to more matches rejected and thus less false positives.  The '''maximal curvature factor''' is the threshold for edge responses as depicted in Figs. 2 and 3.  The value must be >1.0.  Higher values will accept more matches alongside elongated structures and thus lead to potentially more false positives.  '''Second best r/ best r ratio''' is the maximal threshold for non-ambiguous detections.  Higher values will accept more potentially ambiguous matches and thus allow for more false positives.  '''Resolution''' specifies the number of vertices in a long row of the spring mesh as depicted in Fig. 1.  ImageJ lacking support for alpha-channels, you can choose to ignore perfect green (rgb:0,255,0) pixels during ''series alignment''.  This is a hack to cope with montages not covering the whole canvas an will be replaced by a better suited system in the future.  ''Montages'' can be rendered into a green masked canvas accordingly.  Note that the resulting image will be an RGB image in that case.

==References==

<references />
