{{Infobox Plugin
| name                  = TrackMate_
| software             = Fiji
| author                = [[NicholasPerry|Nick Perry]] and [[JeanYvesTinevez|Jean-Yves Tinevez]]
| maintainer         = [mailto:jean-yves.tinevez@pasteur.fr Jean-Yves Tinevez]
| source                = 
| released             = September 13<sup>th</sup>, 2010
| status                 = experimental
| category             = [[:Category:Segmentation|Segmentation]]
}}

== General ==

The TrackMate plugin provides a way to semi-automatically segment "spherical" objects from a 2D or 3D image, and track them over time. Currently, only bright (white) objects on a dark (black) background are supported.

The plugin is logically separated into two distinct steps:

<ol>
<li>
<p><b>Segmentation:</b> The segmentation step identifies where the objects are in the time-lapse image. All objects in all frames are identified in this first step (segmentation and tracking are not performed simultaneously). The method used here is the Laplacian of the Gaussian (LoG), followed by identification of regional maxima, or connected components of pixels with intensity strictly higher than all bordering pixels.</p> 

<p>The result is a candidate list of objects identified within the image. Since this approach to segmentation usually results in many false positives, a thresholding step is incorporated to separate true positives from the false positives. The objects can be thresholded on many features (the LoG value at the center of the object, the average brightness of the object within the expected volume, etc), and an automatic thresholding can be performed for any feature based on histogram thresholding. However, the user retains ultimate control and can threshold objects based on all features in any combination.</p>

<p>Following thresholding, the candidate list of objects is refined to a finalized list of objects, which is used as the input for the tracking step.</p>
</li>

<li>
<p><b>Tracking:</b> The tracking algorithm is an implementation of the algorithm described by Jaqaman, K. et al. in the paper 'Robust single-particle tracking in live-cell time-lapse sequences' (Nature Methods, 2008). In short, this algorithm turns tracking into two separate Linear Assignment Problems (LAPs).</p>

<p>This tracking method is divided into two steps: 

<ol>
<li> Links are made between objects in consecutive frames to create track segments (one-to-one)</li>
<li> Links are made between track segments (merge, split, gap closure). </li>
</ol>
</p>

<p>The tracking algorithm allows for the following, biologically defined events:

<ul>
<li>merging</li>
<li>splitting</li>
<li>disappearance</li>
<li>appearance</li>
</ul>
</p>
</li>
</ol>

== Settings ==

<p>The only required setting is the estimated diameter of the objects being tracked, in physical units.</p>

<p>The user can also choose to modify the calibration settings of the image,  and crop the image in any dimension (x, y, z, as well as t).</p>

== Tutorial ==

[[Category:Segmentation]]
[[Category:Tracking]]
[[Category:Tutorial]]
[[Category:Plugins]]
