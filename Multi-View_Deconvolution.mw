{{Infobox Plugin
| name                   = Multi-view deconvolution plugin
| software               = ImageJ
| author                 = Stephan Preibisch, Fernando Amat, Eugene Myers, Pavel Tomancak
| maintainer             = Stephan Preibisch
| source                 = {{GitLink|jar=SPIM_Registration}}
| filename               = SPIM_Registration.jar
| released               = February 2013
| latest version         = June 2013
| category               = [[:Category:Registration|SPIM Registration]]
| website                = [http://fly.mpi-cbg.de/~preibisch Stephan Preibisch's homepage]
}}

== Overview of the multi-view fusion plugin ==

The multi-view deconvolution plugin is an image fusion plugin that computes one single image from several three-dimensional (3d) acquisitions (views) of the same specimen, taken in different orientations. The deconvolution tries to estimate the most probable image that best explains all views, given the individual point spread function (PSF) of each view. It can be computed for single timepoints or an entire timeseries.

==== Prerequisites I - Registration ====

Prerequisite for the fusion is an aligned dataset, an overview of the complete registration process can be found [[SPIM_Registration|here]], we suggest using the [[SPIM_Bead_Registration|Bead-based registration]] as it provides a simple pipeline.

==== Prerequisites II - PSF's ====

The multi-view deconvolution additionally requires estimates of the PSF for each view. They can be directly and automatically measured from the data itself if fluorescent beads were added to the volume around the sample and the [[SPIM_Bead_Registration|Bead-based registration]] was used to register the views.

Alternatively, an estimate or a simulated PSF can be provided as a 3d image. This is especially helpful in case the registration was achieved in any another way, for example using the [[Segmentation-based registration]] or by an external program.

==== Prerequisites III - Cropping Area ====

It is highly recommended that before starting the multi-view deconvolution, to use the [[Multi-View_Fusion|Multi-view fusion]] in order to determine the right bounding box for the image to be deconvolved.

<span style="color:#A52A2A">
''Note: Do not set the bounding box too close to the imaged sample as it might result in artifacts. A distance of around 30-50 pixels between sample and the bounding box is suggested for the multi-view deconvolution.''
</span>

== How to use the plugin ==

[[Image:Spim multiview dialog1.jpg|thumb|400px|Shows the first dialog that queries the location of the multi-view files]]

The multi-view deconvolution consists like the multi-view fusion of two consecutive dialogs. The first dialog queries the information necessary to analyze the dataset, i.e. locate the image files, the registration information and the location of the corresponding beads if applicable. Please note that all the parameters will be transferred from the [[Multi-View_Fusion|Multi-view fusion]] dialog that you used before to set the bounding box (cropping area).

We omit a detailed explanation of the parameters here as it is identical to the explanation provided [[Multi-View_Fusion#How_to_use_the_plugin|Multi-view fusion dialog]].

After providing the data the plugin will check which kind of registrations are available (*.registration and *.registration_.to{tt}). Typically, the individual registration is available, and maybe also several time-series registrations to various reference timepoints. If no registration files could be found, the plugin will quit.

[[Image:mv_deconvolution.png|thumb|400px|Shows the second dialog that queries detailed parameters]]

In the second dialog, you have to define the detailed instruction of how to run the multi-view deconvolution.

<span style="color:#A52A2A">
''Note: Many of the options that are only mentioned here are explained in detail in the supplement of the not yet published publication. We will upload graphs, comparisons, etc. once the paper is accepted.''
</span>

The available options are:

* '''Registration for channel 0:''' You can choose which registration is used for this channel. You can typically choose between the individual registration of this timepoint or any registration to a reference timepoint.

* '''Crop output image offset x/y/z:''' Defines the offset of the cropping area (bounding box) in the x/y/z-dimension of the output image relative to the uncropped image. A value of 0 refers to the top-front-left corner of the bounding box surrounding all views. 

* '''Crop output image size x/y/z:''' Defines the size of the cropping area (bounding box) in the x/y/z-dimension of the output image relative to the uncropped image. A value of 0 means no cropping.

''Note: The values defining the bounding box are identical to those provided in the multi-view fusion!''

* '''Type of iteration:''' There are several iteration schemes that have been developed and can be used. They differ from each other by convergence time and image quality, which is of course a trade-off:
** ''Fuse all images at once'' loads
